size = 5) +
xlab('Fenoles  [g/kg]') +
ylab('Antioxidantes [mM Fe+2 eq]')
cor.fenol.ax
??correlation
with(miel %>% filter(Localidad == 'Osorno'),
psych::corr.test(fenoles, antioxidantes))
with(miel %>% filter(Localidad == 'Osorno'),
cor(fenoles, antioxidantes))
psych::corr.test(rnorm(10), rnorm(10))
corr.test(attitude)
psych::corr.test(attitude)
miel %>% filter(Localidad == 'Osorno')
miel
miel %>% filter(Localidad == 'Osorno') %>% select(fenoles, antioxidantes)
with(miel %>% filter(Localidad == 'Osorno') %>% select(fenoles, antioxidantes), psych::cor(fenoles, antioxidantes))
with(miel %>% filter(Localidad == 'Osorno') %>% select(fenoles, antioxidantes), psych::corr.test(fenoles, antioxidantes))
df.fenol.ax <- miel %>%
filter(Localidad == 'Osorno') %>%
select(fenoles, antioxidantes)
psych::corr.test(df.fenol.ax)
round(psych::corr.test(df.fenol.ax), 8)
unlink('C:/Users/Carlos Gomez/OneDrive/emejias_paper_junio_2017/Osorno_Avance_figuras_23_julio_2017_cache', recursive = TRUE)
setwd("C:/Users/Carlos Gomez/OneDrive/Analytical/Pagina_Web/test_produccion")
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
paste('Analista ', 1:4)
rep(paste('Analista', 1:4), each = 5)
set.seed(123)
analista <- rep(paste('Analista', 1:4), each = 5)
concentracion <- rnorm(length(analista), 100, 10)
replicado <- rep(1:5, 4)
precision <- data.frame(analista, replicado, concentracion)
precision
kable(precision %>%
spread(., analista, concentracion))
knitr::kable(precision %>%
spread(., analista, concentracion))
library(knitr)
library(kableExtra)
library(tidyverse)
library(readxl)
# library(xlsx)
kable(precision %>%
spread(., analista, concentracion))
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
summary.precision <- precision %>%
group_by(analista) %>%
summary(n = n(),
m = mean(concentracion),
s = sd(concentracion),
se = s/sqrt(n),
ic = qt(0.975, n - 1)*se)
summary.precision
summary.precision <- precision %>%
group_by(analista) %>%
summarise(n = n(),
m = mean(concentracion),
s = sd(concentracion),
se = s/sqrt(n),
ic = qt(0.975, n - 1)*se)
ggplot(summary.precision, aes(x = analista, y = m)) +
geom_point(pch = 19, col = 'red') +
geom_errorbar(aes(ymin = m - s, ymax = m + s), width = 0.1) +
theme_bw() +
ylab('% Cu')
unlink('content/post/2017-08-28-cual-es-la-maxima-diferencia-tolerable-entre-duplicados-de-analisis_cache', recursive = TRUE)
blogdown::serve_site()
blogdown::serve_site()
aov.precision <- aov(concentracion ~ analista, data = precision)
s2r.doe <- round(tidy(aov.precision)[2, 4], 2)
library(broom)
aov.precision <- aov(concentracion ~ analista, data = precision)
s2r.doe <- round(tidy(aov.precision)[2, 4], 2)
s2ana <- round((tidy(aov.precision)[1, 4] - s2r.doe)/5, 2)
s2R <- sqrt(s2r.doe + s2ana)
s2r.doe
blogdown::serve_site()
sqrt(0.03/5)
blogdown::serve_site()
setwd("C:/Users/Carlos Gomez/OneDrive/Analytical/Pagina_Web/cgomez")
blogdown::serve_site()
blogdown:::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::build_site()
blogdown:::new_post_addin()
blogdown::serve_site()
install.packages('nortest')
blogdown:::serve_site()
shapiro.test(rnorm(10000000))
shapiro.test(rnorm(5000))
shapiro.test(rnorm(5000))
shapiro.test(rnorm(5000))
shapiro.test(rnorm(7000))
blogdown:::serve_site()
ad.test(rnorm(10000))
library(nortest)
ad.test(rnorm(10000))
ad.test(rnorm(100000))
ad.test(rnorm(100000))
ad.test(rnorm(1000000))
help(rpois)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
2+2
x <- 2
2*x
6*x
y <- c(0, 10, 20, 30, 40)
2*y
mean(y)
sd(y)
median(y)
mad(y)
Fe <- rnorm(100, 10, 1)
mean(Fe)
sd(Fe)
median(Fe)
mad(Fe)
hist(Fe)
boxplot(Fe)
qqnorm(Fe)
qqline(Fe)
x <- rnorm(100, 10, 1)
x <- rnorm(100, 10, 1)
mean(x)
sd(x)
median(x)
mad(x)
source('~/.active-rstudio-document', echo=TRUE)
x <- rnorm(100, 10, 1)
mean(x)
sd(x)
median(x)
mad(x)
# Cálculo de intervalo de confianza para la media
icsup <- mean(x) + qt(0.975, 99)*sd(x)/sqrt(100)
icinf <- mean(x) - qt(0.025, 99)*sd(x)/sqrt(100)
# concatenar ambos intervaloes
c(icinf, icsup)
source('C:/Users/Carlos Gomez/OneDrive/Analytical/Pagina_Web/cgomez/clase1.R', encoding = 'UTF-8', echo=TRUE)
qt(0.975, 99)
qt(0.025, 99)
source('C:/Users/Carlos Gomez/OneDrive/Analytical/Pagina_Web/cgomez/clase1.R', encoding = 'UTF-8', echo=TRUE)
source('C:/Users/Carlos Gomez/OneDrive/Analytical/Pagina_Web/cgomez/clase1.R', encoding = 'UTF-8', echo=TRUE)
icp <- rnorm(10,100, 5)
faas <- rnorm(10, 100, 5)
shapiro.test(icp)
shapiro.test(faas)
var.test(icp, faas)
var.test(icp, faas)
t.test(icp, faas, var.equal = F)
rt(100, 3)
Cu <- rt(100, 3)
shapiro.test(Cu)
qqnorm(Cu)
qqline(Cu)
cv <- function(x){
sd(x)/mean(x)*100
}
set.seed(123)
t <- rnorm(10, 100, 1)
cv(t)
promedios <- boot(Cu, boot.media, 1000)
library(boot)
promedios <- boot(Cu, boot.media, 1000)
boot.media <- function(x, i){
mean(x[i])
}
library(boot)
promedios <- boot(Cu, boot.media, 1000)
promedios
plot(promedios)
boot.ci(promedios)
library(readxl)
datos <- read_excel("~/datos.xlsx", sheet = "precision")
View(datos)
aov.precision <- aov(Concentracion ~ Analista, data = datos)
boxplot(Concentracion ~ Analista, data = datos)
summary(aov.precision)
plot(aov.precision)
library(readxl)
lof <- read_excel("C:/Users/Carlos Gomez/OneDrive/Curso UChile 2017 Semi/datos taller QAQC 2017.xlsx",
sheet = "Linealidad_LOF")
View(lof)
modelo.lineal <- lm(y ~ x, data = lof)
# Cargamos la librería alr3
library(alr3)
pureErrorAnova(modelo.lineal)
library(readxl)
mandel <- read_excel("C:/Users/Carlos Gomez/OneDrive/Curso UChile 2017 Semi/datos taller QAQC 2017.xlsx",
sheet = "Linealidad_Mandel")
View(mandel)
mandel.lineal <- lm(y ~ x, data = mandel)
mandel.nolineal <- lm(y ~ x + I(x^2), data = mandel)
anova(mandel.lineal, mandel.nolineal)
blogdown::serve_site()
library(ggplot2)
ggplot(data = data.frame(x = c(-3, 3)), aes(x)) +
stat_function(fun = dnorm, n = 101,
args = list(mean = 0, sd = 1),
fill = 'lightblue') +
ylab('f(x)')
ggplot(data = data.frame(x = c(-3, 3)), aes(x, fill = 'lightblue')) +
stat_function(fun = dnorm, n = 101,
args = list(mean = 0, sd = 1)) +
ylab('f(x)')
ggplot(data = data.frame(x = c(-3, 3)), aes(x), fill = 'lightblue') +
stat_function(fun = dnorm, n = 101,
args = list(mean = 0, sd = 1)) +
ylab('f(x)')
ggplot(data = data.frame(x = c(-3, 3)), aes(x), fill = 'lightblue') +
stat_function(fun = dnorm, n = 101,
args = list(mean = 0, sd = 1)) +
ylab('f(x)') +
theme_bw()
ggplot(data = data.frame(x = c(-3, 3)), aes(x), fill = 'lightblue') +
stat_function(fun = dnorm, n = 101,
args = list(mean = 0, sd = 1)) +
ylab('f(x)') +
theme_bw() +
xlim(-3, 3)
ggplot(data = data.frame(x = c(-4, 4)), aes(x)) +
stat_function(fun = dnorm, n = 101,
args = list(mean = 0, sd = 1),
geom = 'area',
fill = 'lightblue',
alpha = 0.3) +
ylab('f(x)') +
theme_bw() +
xlim(-4, 4)
ggplot(data = data.frame(x = c(-4, 4)), aes(x)) +
stat_function(fun = dnorm, n = 101,
args = list(mean = 0, sd = 1),
geom = 'area',
fill = 'lightblue',
alpha = 0.5) +
ylab('f(x)') +
theme_bw() +
xlim(-4, 4)
blogdown::serve_site()
Bangladesh
install.packages("dataset")
install.packages("resampledata")
library(resampledata)
qqnorm(Bangladesh$Arsenic)
blogdown::serve_site()
t <- t.test(Bangladesh$Arsenic)
t
str(t)
t$conf.int
round(t$conf.int,2)
round(t$conf.int,1)
round(t$conf.int,0)
mean(Bangladesh$Arsenic)* qt(0.975, 270)*sd(Bangladesh$Arsenic)/sqrt(271)
mean(Bangladesh$Arsenic)+ qt(0.975, 270)*sd(Bangladesh$Arsenic)/sqrt(271)
mean(Bangladesh$Arsenic)+ qt(0.95, 270)*sd(Bangladesh$Arsenic)/sqrt(271)
mean(Bangladesh$Arsenic)+ qt(0.975, 270)*sd(Bangladesh$Arsenic)/sqrt(271)
blogdown::serve_site()
blogdown::serve_site()
library(boot)
As.boot <- boot(Bangladesh$Arsenic,
function(x, i) mean(x[i]),
R = 100000)
boot.ci(As.boot)
library(boot)
set.seed(123)
As.boot <- boot(Bangladesh$Arsenic,
function(x, i) mean(x[i]),
R = 10000)
boot.ci(As.boot)
As.boot.ci <- boot.ci(As.boot)
As.boot.ci$bca
As.boot.ci$bca[c(4,5)]
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::buuild_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=2
simA <- rnorm(runs,mean=meanA,sd=sigmaA)
simB <- rnorm(runs,mean=meanB,sd=sigmaB)
f=A/B
f
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=2
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=sqrt(f^2*((sigmaA/A)^2+(sigmaB/B)^2-2*sigmaA*sigmaB/A/B))
sigmaf
simf=simA/simB
simf
sd(simf)
hist(simf)
hist(simA)
hist(simB)
hist(simf)
hist(simf, breaks = 100)
hist(simf, xlim = c(-200, 200))
hist(simf, xlim = c(-200, 500))
mean(simf)
median(simf)
mad(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=0.5
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=sqrt(f^2*((sigmaA/A)^2+(sigmaB/B)^2-2*sigmaA*sigmaB/A/B))
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=0.5
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=sqrt(f^2*((sigmaA/A)^2+(sigmaB/B)^2))
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=0.5
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2))
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=0.5
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=1
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=1.5
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=1.1
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=1.2
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=1.3
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=1.4
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=1.5
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=1.5
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
runs = 100000
A=10
sigmaA=1
B=5
sigmaB=1.5
simA <- rnorm(runs,mean=A,sd=sigmaA)
simB <- rnorm(runs,mean=B,sd=sigmaB)
f=A/B
f
sigmaf=f*sqrt((sigmaA/A)^2+(sigmaB/B)^2)
sigmaf
simf=simA/simB
sd(simf)
1.5/5
mean(simf)
mad(simf)
hist(simf)
hist(simf, breaks = 50)
hist(simf, breaks = 100)
blogdown::serve_site()
blogdown::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::build_site()
blogdown:::build_site()
setwd("C:/Users/Carlos Gomez/OneDrive/Analytical/Pagina_Web/testing_BV")
blogdown::new_site(theme = 'gcushen/hugo-academic')
