<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Carlos Gómez</title>
    <link>https://www.analytical.cl/categories/r/</link>
    <description>Recent content in R on Carlos Gómez</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <copyright>&amp;copy; 2017 Carlos Gómez</copyright>
    <lastBuildDate>Fri, 08 Sep 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/categories/r/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>¡Mis datos no son normales! ¿Qué hago?...Cálmese, nunca lo fueron... ni lo serán</title>
      <link>https://www.analytical.cl/post/mis-datos-no-son-normales/</link>
      <pubDate>Fri, 08 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.analytical.cl/post/mis-datos-no-son-normales/</guid>
      <description>&lt;p&gt;Bueno, aquí va la primera piedra:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;No existen datos experimentales normales&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Sus datos obtenidos en el laboratorio no “siguen” ninguna distribución de probabilidad. La naturaleza no “sigue” ninguna distribución de probabilidad.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;La Normalidad es sólo una abstracción, es un modelo matemático de un fenómeno aleatorio.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Y como todo modelo, podría ser razonable para un conjunto de datos y totalmente equivocado para otro. Somos nosotros, los químicos/científicos, quienes proponemos modelos del sistema que estamos estudiando y a través de la experimentación corroboramos o no estos modelos.&lt;/p&gt;
&lt;p&gt;Todos los tests estadísticos formales para evaluar la normalidad tampoco responden en forma 100% certera si esta hipótesis es válida, pues están afectos a los errores de tipo falso positivo (I) y falso negativo (II). Por lo tanto, las pruebas estadísticas en la práctica no confirman que los datos experimentales sean Normales, sino que nos indican si el modelo Normal es razonable o no. Si lo es, actuamos como si “fuesen” normales y hacemos inferencia estadística a partir de las propiedades de la Normal.&lt;/p&gt;
&lt;p&gt;El modelo Normal se describe en la ecuación &lt;a href=&#34;#eq:normal&#34;&gt;(1)&lt;/a&gt; y la figura &lt;a href=&#34;#fig:plotnormal&#34;&gt;1&lt;/a&gt; muestra la archiconocida forma de campana:&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:normal&#34;&gt;\[\begin{equation}
  f(x) = \frac{1}{\sigma \sqrt{2\pi}}\exp{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}
  \tag{1}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;donde &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; y &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; son la desviación estándar y media, respectivamente. Notar que la distribución Normal es aplicable sólo a variables &lt;strong&gt;continuas&lt;/strong&gt;, tales como concentración, temperatura, masa, etc. No se puede aplicar la distribución normal a variables &lt;strong&gt;discretas&lt;/strong&gt; como cuentas de células bajo un campo de microscopio, por ejemplo. Quizás algún microbiólogo está familiarizado con el uso de logaritmos en sus cálculos de incertidumbre, bueno, es porque se utilizan otros modelos de probabilidad para datos discretos (ufc), como el modelo Poisson.&lt;/p&gt;
&lt;p&gt;Advierta también, que los posibles valores que puede tomar la variable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; están en el no despreciable rango entre &lt;span class=&#34;math inline&#34;&gt;\(-\infty\)&lt;/span&gt; y &lt;span class=&#34;math inline&#34;&gt;\(+\infty\)&lt;/span&gt;. ¿Ha comprado algún estándar de calibración cuyo certificado indique una pureza de &lt;span class=&#34;math inline&#34;&gt;\(99.7 \pm 0.5\)&lt;/span&gt; %? Raro ¿no? Bueno, pues el proveedor ha aplicado equivocadamente la distribución Normal a una variable que no es Normal: pureza química. En efecto, desde el punto de vista químico la pureza está confinada al intervalo &lt;span class=&#34;math inline&#34;&gt;\([0, 100]\)&lt;/span&gt; %, por lo tanto, no tiene sentido químico un certificado que indique &lt;span class=&#34;math inline&#34;&gt;\(99.7 \pm 0.5\)&lt;/span&gt; %. Para modelar pureza química es necesario utilizar una distribución de probabilidad que esté restringida al intervalo &lt;span class=&#34;math inline&#34;&gt;\([0, 100]\)&lt;/span&gt; % (o &lt;span class=&#34;math inline&#34;&gt;\([0, 1]\)&lt;/span&gt;) como, por ejemplo, la distribución Beta.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plotnormal&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-09-08-mis-datos-no-son-normales-qué-hago-cálmese-nunca-lo-fueron-ni-lo-serán_files/figure-html/plotnormal-1.png&#34; alt=&#34;Distribución Normal con media = 0 y sd = 1 &#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Distribución Normal con media = 0 y sd = 1
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Existen varios test para evaluar la palusibilidad de la normalidad de los datos, pero en este post discutiremos sólo dos de ellos: El test de Shapiro-Wilk y el Test de Anderson-Darling.&lt;/p&gt;
&lt;p&gt;La matemática detrás de estos tests no es muy digerible, por lo que simplemente los ejemplificaremos con algunos datos reales y simulados. La ventaja de usar simulaciones es que “creamos” artificialmente datos de la distribución que se nos plazca y así verificar el desempeño de estos tests. Si recuerda, ya habíamos utilizado la simulación cuando revisamos las pruebas de linealidad en este &lt;a href=&#34;https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Antes de hacer cualquier prueba estadística de normalidad grafique los datos, a través de un histograma y un gráfico de probabilidad Normal&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Estos gráficos le darán una primera aproximación para evaluar el supuesto de normalidad. Todos los softwares estadísticos incorporan estos gráficos. A continuación los veremos en acción en datos normales simulados en lenguaje &lt;code&gt;R&lt;/code&gt;, qué otro. El siguiente es el código para llevar a cabo esta simulación de &lt;span class=&#34;math inline&#34;&gt;\(n = 100\)&lt;/span&gt; datos normales:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123) # Con este comando nos aseguramos de generar siempre
              # los mismos datos aleatorios. Sino, obviamente, todos
              # generaríamos números distintos pues son aleatorios ¿no?

n &amp;lt;- 100 # Número de datos a simular
mu &amp;lt;- 10 # Media de los n = 100 datos
sigma &amp;lt;- 1 # Desviación estándar de los n = 100 datos

# Genera 100 dato normales con media mu y desviación estándar sigma
# y guárdalos en el vector llamado x
x &amp;lt;- rnorm(n, mu, sigma)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Al calcular la media y desviación estándar (muestral) de estos datos obtenemos &lt;span class=&#34;math inline&#34;&gt;\(\overline{x} = 10.1\)&lt;/span&gt; y &lt;span class=&#34;math inline&#34;&gt;\(s = 0.9\)&lt;/span&gt; “¿Pero cómo? ¿No habíamos simulado una media de 10 y desviación estándar 1? Esto es una estafa” &lt;em&gt;Keep calm&lt;/em&gt; recuerde que son aleatorios. La figura &lt;a href=&#34;#fig:normplot&#34;&gt;2&lt;/a&gt; muestra a la izquierda el histograma y a la derecha el gráfico de normalidad (&lt;em&gt;QQ-Plot&lt;/em&gt;) de los datos simulados:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:normplot&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-09-08-mis-datos-no-son-normales-qué-hago-cálmese-nunca-lo-fueron-ni-lo-serán_files/figure-html/normplot-1.png&#34; alt=&#34;Izquierda histograma, derecha gráfico de normalidad&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Izquierda histograma, derecha gráfico de normalidad
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;El histograma muestra esa forma de campana característica de la distribución normal. Quizás no conozca el gráfico de probabilidad normal o &lt;em&gt;QQ-Plot&lt;/em&gt;, pero es la primera evidencia que un estadístico revisa para evaluar la hipótesis de normalidad. Note que la “mayoría” de los datos está sobre una línea diagonal roja, cuando Ud. observe este patrón podría concluir que el modelo normal es &lt;strong&gt;razonable&lt;/strong&gt; o adecuado para modelar sus datos.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;¿Son concluyentes estos gráficos? No, en absoluto. Simplemente muestran que la normalidad es una hipótesis plausible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Recuerde que estos datos son simulados, por lo tanto, era esperable este comportamiento. Pero sus datos experimentales son “reales”, &lt;em&gt;a priori&lt;/em&gt; no sabe qué comportamiento podrían evidenciar, sólo puede plantear una hipótesis.&lt;/p&gt;
&lt;p&gt;Apliquemos ahora los test “formales” de linealidad: test de Shapiro y test de Anderson. Ambos tests intentan evaluar la hipótesis nula &lt;span class=&#34;math inline&#34;&gt;\(H_{0}\)&lt;/span&gt; que los datos provienen de una distribución Normal:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(nortest) # Cargamos esta librería que contiene varios test de
                 # Normalidad, entre ellos Anderson-Darling

# Test de Shapiro-Wilk (no requiere librería nortest)
shapiro.test(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    Shapiro-Wilk normality test

data:  x
W = 0.99388, p-value = 0.9349&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# test de Anderson-Darling
ad.test(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    Anderson-Darling normality test

data:  x
A = 0.182, p-value = 0.9104&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;La interpretación tradicional de las pruebas de hipótesis sería más o menos la siguiente:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ya que el &lt;em&gt;p-value&lt;/em&gt; &amp;gt; 0,05, entonces, no hay evidencia para rechazar la hipótesis de normalidad de los datos. ¿Se conluye, entonces, que los datos son normales? No. Simplemente, no tenemos la evidencia para rechzar la hipótesis.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Por lo tanto, no es que los datos sean normales, sino que la hipótesis de normalidad es razonable, por lo que actuaremos como si fuese cierto. Obviamente, estos resultados eran esperables pues hemos “creado” datos normales, pero recuerde que sus datos son “reales”, no simulados. Hay otras consideraciones de las pruebas de hipótesis que no mencionaremos por espacio, pero que un post futuro discutiremos en profundidad. Especialmente, esta perversa dicotomía del &lt;em&gt;p-value&lt;/em&gt; &amp;lt; ó &amp;gt; 0,05 de la cual ya hicimos mención en este &lt;a href=&#34;https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The p-value was never intended to be a substitute for scientific reasoning” Ron Wasserstein, Director Ejecutivo de la Asociación Americana de Estadística ASA.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Nota&lt;/strong&gt;: Para tamaños de muestra grandes (&lt;span class=&#34;math inline&#34;&gt;\(n &amp;gt; 1000\)&lt;/span&gt;), una pequeña desviación de la normalidad hará que los tests estadísticos acusen No Normalidad&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Cuando nos referimos a “actuar como si fuese cierto”, estamos diciendo que todos aquellos procedimientos estadísticos que suponen normalidad de los datos, funcionarán de acuerdo a la teoría. ¿Cuáles son estos métodos estadísticos que requieren normalidad de los datos?:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Test de Student en todas sus variantes (es un test de sesgo)&lt;/li&gt;
&lt;li&gt;Test de Fisher para comparar varianzas (precisión analítica de 2 métodos)&lt;/li&gt;
&lt;li&gt;Curva de calibración lineal&lt;/li&gt;
&lt;li&gt;Máxima diferencia tolerable entre duplicados de análisis, discutido &lt;a href=&#34;https://www.analytical.cl/post/cual-maxima-diferencia-tolerable-entre-duplicados-analisis/&#34;&gt;aquí&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Análisis de varianza para evaluar varios métodos analíticos o analistas&lt;/li&gt;
&lt;li&gt;Intervalos de confianza para la media de concentraciones.&lt;/li&gt;
&lt;li&gt;Incertidumbre de métodos analíticos. El &lt;span class=&#34;math inline&#34;&gt;\(k = 2\)&lt;/span&gt; asume normalidad de las concentraciones.&lt;/li&gt;
&lt;li&gt;… y un largo etc.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ok, es cierto, a medida que aumenta el &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; la suposición de normalidad es cada vez menos relevante. De hecho algunos de los tests mencionados arriba son más o menos “robustos” a la suposición de normalidad.&lt;/p&gt;
&lt;div id=&#34;que-observariamos-si-la-hipotesis-de-normalidad-fuese-totalmente-inverosimil-para-modelar-nuestros-datos&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;¿Qué observaríamos si la hipótesis de normalidad fuese totalmente inverosímil para modelar nuestros datos?&lt;/h1&gt;
&lt;p&gt;Simulemos ahora datos no normales y veamos cuáles son los resultados tanto de los gráficos exploratorios como de las pruebas estadísticas formales:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Simularemos m = 100 datos discretos de una distribución Poisson

set.seed (123) # Para que pueda reproducir los datos
m &amp;lt;- 100 # m = 100 datos
lambda &amp;lt;- 5 # Parámetro de la distribución Poisson

# Generar m = 100 datos de una distribución Poisson con parámtro lambda = 5
y &amp;lt;- rpois(m, lambda)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.analytical.cl/post/2017-09-08-mis-datos-no-son-normales-qué-hago-cálmese-nunca-lo-fueron-ni-lo-serán_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;¿No les parece familiar el QQ-Plot a aquellos que validan homogeneidad de peso en validación de procesos farmacéuticos? 1313&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;La evidencia de los gráficos es abrumadora, los datos no son normales. Esto concuerda con lo que muestran los tests estadísticos de normalidad:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Test de Shapiro-Wilk (no requiere librería nortets)
shapiro.test(y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    Shapiro-Wilk normality test

data:  y
W = 0.97077, p-value = 0.02531&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# test de Anderson-Darling
ad.test(y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    Anderson-Darling normality test

data:  y
A = 1.2355, p-value = 0.003072&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Como era esperable, ambos tests confirman que la hipótesis de normalidad no es razonable para modelar los datos(&lt;em&gt;p-value&lt;/em&gt; &amp;lt; 0,05)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;si-mis-datos-no-son-normales-entonces-como-los-analizo&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Si mis datos no son normales, entonces ¿Cómo los analizo?&lt;/h1&gt;
&lt;p&gt;Tranquilo(a), el mundo sigue girando. Existen varios métodos estadísticos que Ud. puede utilizar para analizar datos donde la hipótesis de normalidad no es razonable o se ha demostrado empíricamente que no es :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Bootstrap&lt;/strong&gt;: Utilizado, entre otros propósitos, para obtener intervalos de confianza para datos no normales.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tests no paramétricos&lt;/strong&gt;: Análogos a las pruebas paramétricas tradicionales (Test T, ANOVA, etc.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tests de permutaciones&lt;/strong&gt;: También son una excelente alternativa a las pruebas paramétricas tradicionales y funcionan, incluso, para conjuntos pequeños de datos. Son tests “exactos”, pero necesitan que Ud. disponga de un buen “tarro” (computador) pues son &lt;em&gt;computationally-intensive methods&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modelos lineales generalizados&lt;/strong&gt;: Idóneos para modelar datos discretos como cuentas de células (leucocitos, ufc, etc.) o variables dicotómicas (Conforme/No Conforme), etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformación de datos&lt;/strong&gt;: Especialmente útiles son la transformación de Johnson y la de Box-Cox.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Estadística Robusta&lt;/strong&gt;: No tan sólo son útiles para minimizar el efecto de valores anómalos (&lt;em&gt;outliers&lt;/em&gt;), sino también para obener estimadores de datos que no son normales.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Para finalizar veamos en acción de estos métodos: Bootstrap. Sin embargo, el detalle estadístico y su implementación los veremos en otro post, por ahora, simplemente lo ejemplificaremos. La figura &lt;a href=&#34;#fig:As&#34;&gt;3&lt;/a&gt; muestra el histograma y el &lt;em&gt;QQ-Plot&lt;/em&gt; de normalidad correspondientes a datos de concentración de arsénico [ppm] muestreados en &lt;span class=&#34;math inline&#34;&gt;\(n = 271\)&lt;/span&gt; pozos de agua en Bangladesh:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:As&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-09-08-mis-datos-no-son-normales-qué-hago-cálmese-nunca-lo-fueron-ni-lo-serán_files/figure-html/As-1.png&#34; alt=&#34;Histograma y QQ-Plot datos de Arsénico [ppm] en n = 271 pozos en Bangladesh&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Histograma y QQ-Plot datos de Arsénico [ppm] en n = 271 pozos en Bangladesh
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Claramente, ni si quiera es necesario hacer un test de normalidad, la evidencia que muestra la figura &lt;a href=&#34;#fig:As&#34;&gt;3&lt;/a&gt; en contra de la hipótesis de normalidad es abrumadora. El promedio de la concentración de As es &lt;span class=&#34;math inline&#34;&gt;\(\overline{x} = 125\)&lt;/span&gt; ppm y la desviación estándar &lt;span class=&#34;math inline&#34;&gt;\(s = 298\)&lt;/span&gt; ppm. Utilizando la fórmula usual para estimar un intervalo de confianza al 95% para la media &lt;span class=&#34;math inline&#34;&gt;\(\overline{x} \pm t_{\alpha/2, n - 1} s/\sqrt{n}\)&lt;/span&gt; obtenemos [90, 161] ppm As. Sin embargo, la gran asimetría de los datos hace inverosímil el intervalo obtenido.&lt;/p&gt;
&lt;p&gt;Al aplicar el método &lt;em&gt;bootstrap&lt;/em&gt; obtenemos un intervalo para la media al 95% (BCa) entre [98, 175] ppm As, el cual es más “correcto” por si Ud. necesita informar este parámetro. La figura &lt;a href=&#34;#fig:Asboot&#34;&gt;4&lt;/a&gt; muestra el histograma y QQ-Plot de normalidad de el método de bootstrap. Advierta el Teorema Central del Límite en su máxima expresión.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:Asboot&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-09-08-mis-datos-no-son-normales-qué-hago-cálmese-nunca-lo-fueron-ni-lo-serán_files/figure-html/Asboot-1.png&#34; alt=&#34;Histograma y QQ-Plot de las estimaciones de la media de los datos de As con N = 1000 remuestreos&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Histograma y QQ-Plot de las estimaciones de la media de los datos de As con N = 1000 remuestreos
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Bueno estimado lector, nos vemos pronto. Saludos.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bibliografia&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bibliografía&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Ghasemi A, Zahediasl S. Normality Tests for Statistical Analysis: A Guide for Non-Statisticians. &lt;em&gt;International Journal of Endocrinology and Metabolism&lt;/em&gt;. 2012;10(2):486-489. &lt;a href=&#34;doi:10.5812/ijem.3505&#34; class=&#34;uri&#34;&gt;doi:10.5812/ijem.3505&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Henry C. Thode &lt;em&gt;Testing For Normality&lt;/em&gt; CRC Press 2002&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://bit.ly/2pfPsRg&#34;&gt;Is normality testing ‘essentially useless’?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>¿Cuál es la máxima diferencia tolerable entre duplicados de análisis?</title>
      <link>https://www.analytical.cl/post/cual-maxima-diferencia-tolerable-entre-duplicados-analisis/</link>
      <pubDate>Mon, 28 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.analytical.cl/post/cual-maxima-diferencia-tolerable-entre-duplicados-analisis/</guid>
      <description>&lt;p&gt;Un día cualquiera en un laboratorio que aún no establece criterios de aceptación de precisión:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Duplicado 1 = 25.56 % Cu&lt;/li&gt;
&lt;li&gt;Duplicado 2 = 25.66 % Cu&lt;/li&gt;
&lt;li&gt;Diferencia = 0.10 % Cu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La diferencia observada ¿es aceptable para el laboratorio?&lt;/p&gt;
&lt;p&gt;Para responder a esta pregunta debemos considerar varias cosas:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;¿Los duplicados fueron realizados en condiciones de repetibilidad o reproducibilidad?&lt;/li&gt;
&lt;li&gt;¿Existe alguna normativa al respecto que se deba cumplir?&lt;/li&gt;
&lt;li&gt;¿Cuál es la metodología analítica? No es lo mismo determinar Cu en concentrado de cobre por electrogravimetría (método primario) que por Fluorescencia de Rayos X.&lt;/li&gt;
&lt;li&gt;¿Cuál es la incertidumbre del método analítico?&lt;/li&gt;
&lt;li&gt;¿Existe algún acuerdo a nivel comercial sobre estas diferencias?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Para abordar este problema tendremos que hace la suposición que los duplicados fueron obtenidos en condiciones de repetibilidad, es decir: mismo analista, mismo día, mismo instrumento, etc. Bajo esta premisa hay varias formas de estimar la máxima diferencia tolerable entre duplicados de análisis.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Nota&lt;/strong&gt;: En realidad, los conceptos que mostraremos a continuación son completamente análogos para estimar la máxima diferencia tolerable en condiciones de reproducibilidad. Sin embargo, dedicaremos otro post a ese tema específico.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;El concepto estadístico clave para establecer la tolerancia entre duplicados es el límite de repetibilidad &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;limite-de-repetibilidad-r-iso-5725&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Límite de repetibilidad &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; ISO 5725&lt;/h1&gt;
&lt;p&gt;La guía ISO 5725 define el límite de repetibilidad &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; de la siguiente manera:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
r = 2.8\cdot s_{r}
\]&lt;/span&gt; y corresponde a la máxima diferencia, en valor absoluto, que puede tolerarse entre duplicados de análisis, obtenidos bajo condiciones de repetibilidad con un 95% de confianza. Veamos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{r}\)&lt;/span&gt; es la desviación estándar de repetibilidad, la cual da cuenta de la dispersión de las diferencias entre duplicados. Ya explicaremos cómo calcular este parámetro.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;El factor &lt;strong&gt;2.8&lt;/strong&gt;: aquí les exijo una prueba de fe mis hermanos, me tienen que creer porque si quieren la demostración, aumentaría mucho la viscosidad de este post . A &lt;em&gt;grosso modo&lt;/em&gt;, el factor 2.8 tiene que ver con el 95% de confianza, nos indica que cuando se establece la máxima diferencia tolerable, está permitido que el 5% de los duplicados estén fuera del límite &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;, y aún el sistema analítico se encontraría bajo &lt;em&gt;Control Estadístico&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;como-obtenemos-la-precision-de-repetibilidad-s_r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;¿Cómo obtenemos la precisión de repetibilidad &lt;span class=&#34;math inline&#34;&gt;\(s_{r}\)&lt;/span&gt;?&lt;/h1&gt;
&lt;p&gt;Existen varios métodos estadísticos para abordar la estimación de la desviación estándar de repetibililidad &lt;span class=&#34;math inline&#34;&gt;\(s_{r}\)&lt;/span&gt;, sin embargo, en este post nos enfocaremos en los dos más utilizados en química analítica:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Estimación basada en el registro histórico de duplicados de análisis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;La estimación mediante estudios de precisión siguiendo las directrices de la guía ISO 5725.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;No describiremos todos los detalles de cada uno de los diseños experimentales expuestos en estas guías, más bien, ejemplificaremos el cálculo de la desviación estándar de repetibilidad &lt;span class=&#34;math inline&#34;&gt;\(s_{r}\)&lt;/span&gt;:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;metodo-de-estimacion-en-base-a-datos-historicos-de-duplicados&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Método de estimación en base a datos históricos de duplicados&lt;/h1&gt;
&lt;p&gt;Obviamente necesitamos crear una base de datos con los registros de análisis de muestras en duplicados en condiciones de repetibilidad. Estas muestras pueden corresponder a muestras de clientes, materiales de referencia primarios o secundarios, muestras control, etc. Lo importante es que ambos duplicados cumplan con las condiciones de repetibilidad. La tabla &lt;a href=&#34;#tab:bdsr&#34;&gt;1&lt;/a&gt; es un ejemplo de una base de datos a utilizar en este método:&lt;/p&gt;
&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:bdsr&#34;&gt;Table 1: &lt;/span&gt;Base de datos histórica de duplicados (sólo los primeros 6 datos)
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
ID
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Duplicado 1
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Duplicado 2
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
QAQC-01
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30.79
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30.54
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
QAQC-02
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
31.89
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
32.04
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
QAQC-03
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
31.28
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
31.32
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
QAQC-04
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
31.30
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30.89
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
QAQC-05
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30.70
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30.66
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
QAQC-06
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30.86
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30.69
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Puede descargar esta base de datos desde este &lt;a href=&#34;https://1drv.ms/x/s!AuF6FPVWruwDtoUe9jzqyzQ_q1HFwg&#34;&gt;link&lt;/a&gt;. Y ahora la pregunta del millón: ¿Cuántas muestras en duplicado necesito? Si bien es posible obtener un cálculo “exacto” del número de muestras &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;, esto está fuera del alcance de este post. Sin embargo, podemos decir que &lt;span class=&#34;math inline&#34;&gt;\(n &amp;gt; 25\)&lt;/span&gt; es un número inicial adecuado.&lt;/p&gt;
&lt;p&gt;Una vez construida la base de datos, se puede obtener una estimación de &lt;span class=&#34;math inline&#34;&gt;\(s_{r}\)&lt;/span&gt; mediante la ecuación &lt;a href=&#34;#eq:srdup&#34;&gt;(1)&lt;/a&gt;:&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:srdup&#34;&gt;\[\begin{equation}
  s_{r} = \sqrt{\frac{\sum_{i = 1}^{n} (x_{i1} - x_{i2})^2}{2n}}
  \tag{1}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;Esta ecuación puede ser fácilmente implementada en Excel pero en este post, como no, haremos los cálculos en lenguaje R. Pero antes, observe la figura &lt;a href=&#34;#fig:dup&#34;&gt;1&lt;/a&gt; la cual muestra un gráfico de dispersión entre Duplicado 1 (&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;) y Duplicado 2 (&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;). En este caso el orden es irrelevante. Si ajustáramos un modelo lineal entre ambas variables ¿Qué valores de pendiente e intercepto deberíamos obtener?&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dup&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-08-28-cual-es-la-maxima-diferencia-tolerable-entre-duplicados-de-analisis_files/figure-html/dup-1.png&#34; alt=&#34;Gráfico de dispersión entre duplicados&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Gráfico de dispersión entre duplicados
&lt;/p&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;¡Correcto! Pendiente &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1} = 1\)&lt;/span&gt; e intercepto &lt;span class=&#34;math inline&#34;&gt;\(\beta_{0} = 0\)&lt;/span&gt;. La línea roja representa esta recta teórica. Note también que la dispersión de los datos es constante en todo el rango de concentración, propiedad denominada &lt;strong&gt;Homocedasticidad&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Esta propiedad es deseable, sin embargo, no todos los sistemas analíticos la poseen. En sí misma no es una problema, sin embargo, si la varibilidad de los duplicados aumenta con la concentración (&lt;em&gt;heterocedasticidad&lt;/em&gt;) tendremos que modelar esta variabilidad en función de la concentración en forma explícita o segmentar el rango, lo cual veremos en otro post.&lt;/p&gt;
&lt;p&gt;También advierta la presencia de datos alejados de la diagonal, es decir, diferencias entre duplicados grandes. ¿Qué hacemos con ellos?¿Los mantenemos o los eliminamos?&lt;/p&gt;
&lt;p&gt;Si los eliminamos, y realmente reflejaran la variabilidad del método, entonces subestimaríamos la máxima diferencia tolerable entre duplicados, aumentando la frecuencia de alertas de duplicados no conformes (nos ponemos la soga al cuello solitos). Si los mantenemos, y realmente fueron &lt;em&gt;errores&lt;/em&gt; puntuales de medición, sobreestimaríamos la tolerancia y la carta control sería de poca utilidad (mágicamente todos los datos caerían siempre dentro del los límites). Este tema lo abordaremos en otro post (llevo una lista).&lt;/p&gt;
&lt;p&gt;Como dato “anecdótico” en las operaciones de &lt;em&gt;trading&lt;/em&gt; en el mercado mundial de concentrado de cobre, la máxima diferencia tolerable entre resultados de distintos laboratorios (a.k.a exportador v/s importador) es 0,20 % Cu. Si la diferencia supera este límite, ambos negociadores se van a un arbitraje (multiplique 0,15 % Cu por la millones de toneladas que se transan en el mercado…a 3 US/libra no es un asunto trivial).&lt;/p&gt;
&lt;p&gt;Utilizando los datos históricos estimamos una desviación estándar de repetibilidad de &lt;span class=&#34;math inline&#34;&gt;\(s_{r} = 0.2\)&lt;/span&gt; % Cu. Por lo tanto, el límite de repetibilidad es obtenido de la ecuación &lt;a href=&#34;#eq:limr&#34;&gt;(2)&lt;/a&gt;:&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:limr&#34;&gt;\[\begin{eqnarray}
  r &amp;amp;=&amp;amp; 2.8\cdot s_{r} \\
  r &amp;amp;=&amp;amp; 2.8\cdot 0.2 \\
  r &amp;amp;=&amp;amp; 0.57\, \text{% Cu}
  \tag{2}
\end{eqnarray}\]&lt;/span&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Interpretación&lt;/strong&gt;: La máxima diferencia tolerable, en valor absoluto, entre duplicados de análisis en condiciones de repetibilidad es &lt;span class=&#34;math inline&#34;&gt;\(r = 0.57\)&lt;/span&gt; % Cu.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Entonces, dados los datos iniciales:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Duplicado 1 = 25.56 % Cu&lt;/li&gt;
&lt;li&gt;Duplicado 2 = 25.66 % Cu&lt;/li&gt;
&lt;li&gt;Diferencia = 0.10 % Cu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La diferencia encontrada entre duplicados &lt;span class=&#34;math inline&#34;&gt;\(\Delta = 0.1 &amp;lt; 0.57\)&lt;/span&gt; % Cu, por lo tanto, se acepta la diferencia entre duplicados, es un dato de QAQC conforme.&lt;/p&gt;
&lt;p&gt;¿Y qué hacemos si no tenemos datos históricos de duplicados? Por favor, continue leyendo.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimacion-mediante-estudios-de-precision-siguiendo-las-directrices-de-la-guia-iso-5725&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimación mediante estudios de precisión siguiendo las directrices de la guía ISO 5725&lt;/h1&gt;
&lt;p&gt;Cuando no existen datos históricos, la guía ISO 5725 sugiere llevar a cabo un diseño experimental en el cual se estudien diversos factores que podrían, eventualmente, tener un efecto importante en la precisión del método analítico. Por ejemplo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analistas distintos&lt;/li&gt;
&lt;li&gt;Equipos de medición (cromatógrafos, AAS, etc.)&lt;/li&gt;
&lt;li&gt;Días distintos&lt;/li&gt;
&lt;li&gt;Etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El “problema” de esta aproximación es que a medida que crece el número de factores, el tamaño del diseño experimental (a.k.a número de experientos) crece en forma rápida incluso, en algunos diseños, en forma exponencial.&lt;/p&gt;
&lt;p&gt;La ventaja de este método es que permite estimar en un único estudio la precisión de repetibilidad, reproducibilidad y la precisión intermedia, es decir, entre-analistas, entre-equipos, etc. La otra ventaja es que permite estimar los denominados componentes de varianza “¿Y?” – se preguntará. Bueno, los componentes de varianza nos indican cuál es el factor que más aporta a la variabilidad del sistema analítico ¿será la variabilidad entre-analistas? ¿o los distintos equipos que dispone el laboratorio? De esta forma Ud. podrá focalizar los esfuerzos y recursos en mejorar la precisión del método sólo en aquellos factores que más aporten a la variabilidad total.&lt;/p&gt;
&lt;p&gt;Veamos en qué consiste este método de estimación de precisión en base al estudio del factor &lt;strong&gt;Analista&lt;/strong&gt;. Existen varios diseños experimentales para evaluar este factor, sin embargo, en este post comenzaremos con algo &lt;em&gt;light&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Estimaremos la precisión de reptibilidad y reproducibilidad del método volumétrico para la determinación de Cu en concentrado de cobre, en un laboratorio donde &lt;span class=&#34;math inline&#34;&gt;\(n = 4\)&lt;/span&gt; analistas son igualmente competentes para llevar a cabo el análisis, siguiendo el mismo instructivo.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Para abordar este objetivo, proponemos el siguiente diseño experimental:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://www.analytical.cl/img/doe.png&#34; alt=&#34;Diseño Experimental&#34; width=&#34;700&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Diseño Experimental&lt;/p&gt;
&lt;/div&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Una única muestra será analizada por los &lt;span class=&#34;math inline&#34;&gt;\(n = 4\)&lt;/span&gt; analistas.&lt;/li&gt;
&lt;li&gt;Cada analista realizará el análisis en quintuplicado &lt;span class=&#34;math inline&#34;&gt;\(j = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Los &lt;span class=&#34;math inline&#34;&gt;\(k = n\cdot j = 20\)&lt;/span&gt; análisis deben ser obtenidos en condiciones de repetibilidad&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Si bien podríamos publicar una enciclopedia de posts sobre diseño experimental en química, surgen algunas preguntas sobre este diseño en particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;¿Por qué una única muestra? Porque si cada analista recibiera una muestra distinta, entonces la precisión del factor analista estaría “contaminada” con la variabilidad entre muestras, la cual no nos interesa en este estudio.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;¿Y si una única muestra no es suficiente para llevar a cabo los 20 análisis? Existen otros diseños experimentales denominados &lt;em&gt;anidados&lt;/em&gt; que permiten estimar la precisión utilizando muestras distintas.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;¿Por qué los análisis de cada analista deben ser obtenidos en condiciones de repetibilidad? Porque no queremos que otro factor no controlado (por ejemplo, equipos distintos) influya en la estimación de la precisión entre-analistas.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;En lo posible, aumente el número de analistas en vez de hacer muchos replicados. Es mejor 5 analistas en triplicado, que 3 en quintuplicado.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“La” muestra podría corresponder a una muestra del cliente. No es necesario que sea un material de referencia, sin embargo, esta muestra debe ser lo suficientemente homogénea… ¡Ah, eso es trampa! ¿Cómo demostramos que la muestra es homogénea? Le doy un dato, anote:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Si su muestra es material particulado, le tengo malas noticias: No existen las muestras homogéneas de este tipo de material (gracias a san Pierre Gy por el dato).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Como mencionamos anteriormente podríamos postear &lt;em&gt;ad infinitum&lt;/em&gt; sobre diseño de exprimentos en química, sin embargo, la banda ancha es finita así que vamos al grano. La tabla &lt;a href=&#34;#tab:doe&#34;&gt;2&lt;/a&gt; muestra los datos experimentales del estudio de precisión propuesto:&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:doe&#34;&gt;Table 2: &lt;/span&gt;Resultados de estudio de precisión [% Cu]
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Replicado
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Analista 1
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Analista 2
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Analista 3
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Analista 4
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
24.74
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
24.73
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.06
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.06
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.16
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.17
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
24.98
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.34
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
24.98
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.24
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
24.79
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.28
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.11
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
24.80
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
24.65
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.02
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
24.72
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
25.11
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
24.82
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Antes de llevar a cabo el análisis estadístico formal, observemos la figura &lt;a href=&#34;#fig:doeplot&#34;&gt;2&lt;/a&gt; la cual muestra el valor promedio de cada analista &lt;span class=&#34;math inline&#34;&gt;\(\pm\)&lt;/span&gt; 1 desviación estándar. Ella nos indica que, aparentemente, los resultados entre los analistas son bastante consistentes.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:doeplot&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-08-28-cual-es-la-maxima-diferencia-tolerable-entre-duplicados-de-analisis_files/figure-html/doeplot-1.png&#34; alt=&#34;Boxplot estudio de precisión&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Boxplot estudio de precisión
&lt;/p&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Ahora bien ¿Cómo, entonces, estimamos la precisión de repetibilidad y reproducibilidad a partir de la tabla &lt;a href=&#34;#tab:doe&#34;&gt;2&lt;/a&gt;? Fácil, con el todopoderoso Análisis de Varianza (ANOVA).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;No detallaremos la matemática detrás de esta poderosa técnica, sin embargo, diremos simplemente que el ANOVA es un método cuyo propósito es particionar la variabilidad total de un conjunto de datos en componentes que intentan explicarla. Aplicada a nuestro caso, utilizaremos ANOVA para particionar la variabilidad total de los 20 resultados de % Cu entre dos componentes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;El factor analista&lt;/li&gt;
&lt;li&gt;La repetiblidad del método analítico.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;para lo cual seguiremos paso a paso las instrucciones de la guía ISO 5725. En primer lugar obtendremos la tabla ANOVA mediante lenguaje &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:aov&#34;&gt;Table 3: &lt;/span&gt;Tabla ANOVA precisión
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Origen Variación
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
g.l
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
SQ
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
MS
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
F calculado
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
p-value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
analista
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.07
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1.8
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.19
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Residuals
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.6
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.04
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Las tablas ANOVA muy similares en casi todos los softwares estadísticos profesionales… y en Excel también. Entonces:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Repetibilidad &lt;span class=&#34;math inline&#34;&gt;\(s_{r}\)&lt;/span&gt;: Es simplemente la raíz cuadrada del término &lt;span class=&#34;math inline&#34;&gt;\(MS\)&lt;/span&gt; de los &lt;strong&gt;Residuos&lt;/strong&gt;. En la nomenclatura de ANOVA es lo que se conoce como variabilidad dentro (&lt;em&gt;within&lt;/em&gt;). Para los datos de la tabla &lt;a href=&#34;#tab:doe&#34;&gt;2&lt;/a&gt; se obtiene &lt;span class=&#34;math inline&#34;&gt;\(s_{r} = \sqrt{\text{MS}_{Residuals}} = \sqrt{0.04} = 0.19\)&lt;/span&gt; % Cu.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Precisión intermedia o variabilidad entre-analistas &lt;span class=&#34;math inline&#34;&gt;\(s_{analista}\)&lt;/span&gt;: ¡No tan rápido! No es la raíz cuadrada de &lt;span class=&#34;math inline&#34;&gt;\(MS\)&lt;/span&gt; del factor analista. Debemos hacer el siguiente cálculo adicional:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{eqnarray}
  s_{analista} &amp;amp;=&amp;amp; \sqrt{\frac{MS_{analista} - MS_{Residuals}}{j}} \\
  s_{analista} &amp;amp;=&amp;amp; \sqrt{\frac{0.07 - 0.04}{5}} \\
  s_{analista} &amp;amp;=&amp;amp; 0.08\, \text{% Cu} 
\end{eqnarray}\]&lt;/span&gt;
&lt;p&gt;donde &lt;span class=&#34;math inline&#34;&gt;\(j = 5\)&lt;/span&gt; es el número de replicados que hizo cada analista&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reproducibilidad &lt;span class=&#34;math inline&#34;&gt;\(s_{R}\)&lt;/span&gt;: Es simplemente la combinación en cuadratura de las precisiones arriba calculadas.&lt;/li&gt;
&lt;/ul&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{eqnarray}
  s_{R} &amp;amp;=&amp;amp; \sqrt{s_{r}^{2} + s_{analista}^2}\\
  s_{R} &amp;amp;=&amp;amp; 0.21\, \text{% Cu}
\end{eqnarray}\]&lt;/span&gt;
&lt;p&gt;Por lo tanto, con estos datos podemos calcular el límite de repetibilidad sin necesidad de tener una base de datos histórica de duplicados. En este caso &lt;span class=&#34;math inline&#34;&gt;\(r = 2.8 s_{r} = 0.58\)&lt;/span&gt; % Cu.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;¿Y si quisiera establecer la máxima diferencia tolerable entre analistas?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Nos vemos en el siguiente post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bonus-track-breve-historia-del-factor-2.8&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;em&gt;Bonus track&lt;/em&gt; : Breve historia del factor 2.8&lt;/h1&gt;
&lt;p&gt;Sea &lt;span class=&#34;math inline&#34;&gt;\(x_{1}\)&lt;/span&gt; y &lt;span class=&#34;math inline&#34;&gt;\(x_{2}\)&lt;/span&gt; los duplicados de análisis 1 y 2, respectivamente. Cada uno de ellos “sigue” una distribución Normal con media &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; y varianza &lt;span class=&#34;math inline&#34;&gt;\(V = \sigma_{r}^2\)&lt;/span&gt; y, además, entre ellos son &lt;em&gt;independientes&lt;/em&gt;, entonces se cumple lo siguiente:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;la diferencia entre duplicados &lt;span class=&#34;math inline&#34;&gt;\(\Delta = x_{1} - x_{2}\)&lt;/span&gt; sigue una distribución Normal con media 0 y varianza &lt;span class=&#34;math inline&#34;&gt;\(V_{\Delta} = V(x_{1} - x_{2}) = V(x_{1}) + V(x_{2}) = 2\sigma_{r}^2\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Si la varianza de las diferencias es &lt;span class=&#34;math inline&#34;&gt;\(V_{\Delta} = 2\sigma_{r}^2\)&lt;/span&gt;, entonces la desviación estándar es &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{2} \sigma_{r}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Por lo tanto, si quisiéramos construir un intervalo de confianza al 95% para la diferencia entre duplicados obtendríamos &lt;span class=&#34;math inline&#34;&gt;\(\Delta \pm 2\sqrt{2} \sigma_{r}\)&lt;/span&gt;. El 2 es por que para una distribución Normal se sabe que entre la media &lt;span class=&#34;math inline&#34;&gt;\(\pm\)&lt;/span&gt; 2 la desviación estándar se encuentran aproximadamente el 95% de las observaciones.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(s_{r}\)&lt;/span&gt; es la estimación de &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{r}\)&lt;/span&gt;, la cual es fija pero desconocida.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Como &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{2}\approx 1,41\)&lt;/span&gt; entonces, con un 95% de confianza, la diferencia se encuentra entre &lt;span class=&#34;math inline&#34;&gt;\(\Delta \pm 2\cdot 1,41 \cdot s_{r} = 2.8\cdot s_{r}\)&lt;/span&gt;. Ahora imágineme como el mago Tamariz al final de sus actos tocando el violín ¡chiararaaá! (Si eres &lt;em&gt;old school&lt;/em&gt; sabrás quien es el mago Tamariz. Si eres &lt;em&gt;millenial&lt;/em&gt; mira este &lt;a href=&#34;https://www.youtube.com/watch?v=zcSqG2v-MZQ&#34;&gt;video&lt;/a&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;bibliografia&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bibliografía&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;ISO 5725 – 3:1994 Accuracy (trueness and precision) of measurement methods and results – Part 3: Intermediate measures of the precision of a standard measurement method&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Michael Thompson, Bertil Magnusson Methodology in internal quality control of chemical analysis &lt;em&gt;Accreditation and Quality Assurance August 2013, Volume 18, Issue 4, pp 271–278&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>¿Cómo &#34;demuestro&#34; que mi curva de calibracion es lineal?</title>
      <link>https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/</link>
      <pubDate>Wed, 23 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/</guid>
      <description>&lt;!-- Promedín: Lo siento, no se puede demostrar eso. Fin del Post.\ --&gt;
&lt;!-- Preguntín: &#34;¡Pero cómo!... si el r = 0,999&#34;&#34; \ --&gt;
&lt;!-- Promedín: Lo lamento, el coeficiente de correlación no es una prueba formal de linealidad. --&gt;
&lt;p&gt;En este post intentaremos derribar el mito del coeficiente de correlación con “muchos” 9’s como prueba de linealidad. Además, presentaremos dos test formales para evaluar el modelo de calibración lineal en química analítica.&lt;/p&gt;
&lt;div id=&#34;coeficiente-de-correlacion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Coeficiente de correlación&lt;/h1&gt;
&lt;p&gt;Este parámetro estadístico indica la fuerza y dirección de la relación de dos variables cuantitativas, por ejemplo;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Concentración (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) y Absorbancia (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;)&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(log \text{ Concentración}\)&lt;/span&gt; y &lt;span class=&#34;math inline&#34;&gt;\(E\)&lt;/span&gt; Potencial (Ecuación de Nernst)&lt;/li&gt;
&lt;li&gt;La edad de las ganadoras de Miss América con los asesinatos utilizando objetos calientes y vapor. ¡Cuidado con las correlaciones &lt;a href=&#34;http://tylervigen.com/spurious-correlations&#34;&gt;espurias&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Todos los químicos estamos familiarizados con la ecuación de Lambert-Beer, la cual establece la archiconocida relación entre absorbancia y concentración en métodos espectrofotométricos:&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:lambert&#34;&gt;\[\begin{equation}
  \underbrace{A}_\text{y} = \underbrace{\epsilon \cdot b}_\text{$\beta_{1}$} \cdot
  \underbrace{C}_\text{x}
    \tag{1}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;De la ecuación &lt;a href=&#34;#eq:lambert&#34;&gt;(1)&lt;/a&gt; se observa claramente la relación con el modelo estándar de calibración lineal &lt;span class=&#34;math inline&#34;&gt;\(y = \beta_{0} + \beta_{1}x\)&lt;/span&gt; asumiendo un intercepto &lt;span class=&#34;math inline&#34;&gt;\(\beta_{0} = 0\)&lt;/span&gt;. Por lo tanto ¿por qué nos sorprende tanto encontrar un coeficiente de correlación alto en curvas de calibración espectrofotométricas? Era totalmente esperable, pues hay un modelo físico-químico que sustenta el modelo lineal.&lt;/p&gt;
&lt;p&gt;OK, de acuerdo. Este modelo físico-químico sólo es válido bajo ciertas condiciones (como todos los modelos), de hecho son conocidas las desviaciones de la ley de Lambert-Beer a altas concentraciones.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;derribando-el-mito-del-r-0999&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Derribando el mito del r = 0,999…&lt;/h1&gt;
&lt;p&gt;Para comenzar, por favor, ponga atención a la figura &lt;a href=&#34;#fig:anscombe&#34;&gt;1&lt;/a&gt; denominada “El Cuarteto de Anscombe”. La “gracia” de estos datos de calibración es que todos tienen la misma pendiente, intercepto, error de calibración y… ¡coeficiente de correlación!&lt;/p&gt;
&lt;p&gt;¿No me cree? Le dejo este &lt;a href=&#34;https://1drv.ms/x/s!AuF6FPVWruwDtfpb0dC8SSaBCChfzA&#34;&gt;link&lt;/a&gt; para que descargue los datos en archivo Excel y se convenza con sus propios ojos.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:anscombe&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-08-23-como-demuestro-que-mi-curva-de-calibracion-es-lineal_files/figure-html/anscombe-1.png&#34; alt=&#34;El Cuarteto de Ascombe&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: El Cuarteto de Ascombe
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;El punto que revela la figura &lt;a href=&#34;#fig:anscombe&#34;&gt;1&lt;/a&gt; es que es posible obtener coeficientes de correlación “altos” inclusive con datos que, a simpe vista, no revelan una relación lineal entre &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; e &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. Es más, es posible obtener un alto coeficiente de correlación donde no existe absolutamente ninguna correlación entre &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; e &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; mediante un mal de diseño de la curva de calibración. Por ejemplo, en la figura &lt;a href=&#34;#fig:influyente&#34;&gt;2&lt;/a&gt; se muestra a la izquierda que la correlación entre &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; e &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; es prácticamente 0. Sin embargo, cuando incluimos un punto &lt;em&gt;influyente&lt;/em&gt;, muy alejado de la nube de puntos a baja concentración, mágicamente el r = 1 (derecha).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Moraleja:&lt;/em&gt; Trate, en lo posible, de diseñar la curva con los puntos equiespaciados y evite los saltos de varios órdenes de magnitud de la concentración.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:influyente&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-08-23-como-demuestro-que-mi-curva-de-calibracion-es-lineal_files/figure-html/influyente-1.png&#34; alt=&#34;Punto inlfuyente en la calibración&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Punto inlfuyente en la calibración
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;La linealidad tampoco es un parámetro cuantitativo, una curva con r = 0,999 no es más lineal que otra con r = 0,99. Observe la figura &lt;a href=&#34;#fig:simplot&#34;&gt;3&lt;/a&gt;, ambas curvas fueron simuladas en lenguaje &lt;code&gt;R&lt;/code&gt; con el mismo intercepto y pendiente siguiendo estrictamente el modelo lineal &lt;span class=&#34;math inline&#34;&gt;\(y = \beta_{0} + \beta_{1}x\)&lt;/span&gt;, sin embargo, tienen coeficientes de correlación distintos. La curva de la izquierda no es más lineal que la de la derecha ya que ambas fueron simuladas a partir del mismo modelo, la única diferencia es que la de la derecha tiene una mayor dispersión de los puntos, pero no por ello es “menos lineal”, de hecho ambas lo son, pues fueron simuladas.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123) # Es para que Ud. obtenga los mismos 
              # resultados en su simulación en R
              

b0 &amp;lt;- 1  # Intercepto = 1
b1 &amp;lt;- 10 # Pendiente = 10
s &amp;lt;- 1   # Desviación estándar de calibración

# Simulamos el mismo modelo lineal 
x &amp;lt;- 1:10 # Calibrantes
y1 &amp;lt;- b0 + b1*x + rnorm(10, 0, s) # Absorbancias con 
                                  # error = s = 1
y2 &amp;lt;- b0 + b1*x + rnorm(10, 0, 10*s) # Absorbancias con 
                                     # error = 10*s = 10&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:simplot&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-08-23-como-demuestro-que-mi-curva-de-calibracion-es-lineal_files/figure-html/simplot-1.png&#34; alt=&#34;Simulación de curvas perfectamente lineales&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Simulación de curvas perfectamente lineales
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;test-formales-de-linealidad&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Test formales de linealidad&lt;/h1&gt;
&lt;p&gt;Existen varios tests estadísticos formales para evaluar el supuesto de linealidad de la curva de calibración. Sin embargo, en este post veremos dos que son los más utilizados en Química Analítica y son sugeridos por normativas internacionales (para presentárselos a los amables auditores).&lt;/p&gt;
&lt;p&gt;Si bien no es estrictamente riguroso, para simplificar el concepto, diremos que ambos tests estadísticos intentan dirimir entre dos hipótesis:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_{0}\)&lt;/span&gt; (a.k.a Hipótesis Nula) : El modelo lineal es adecuado para describir los datos de calibración&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_{1}\)&lt;/span&gt; (a.k.a Hipótesis alternativa): El modelo lineal &lt;strong&gt;NO&lt;/strong&gt; es adecuado para describir los datos de calibración&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;También debemos hacer la siguiente acotación: En &lt;strong&gt;estadística&lt;/strong&gt; un modelo lineal es aquel en que sus parámetros son lineales. Por ejemplo, la curva de calibración lineal clásica &lt;span class=&#34;math inline&#34;&gt;\(y = \beta_{0} + \beta_{1}x\)&lt;/span&gt; tanto &lt;span class=&#34;math inline&#34;&gt;\(\beta_{0}\)&lt;/span&gt; y &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1}\)&lt;/span&gt; son lineales. Sin embargo, en un modelo exponencial &lt;span class=&#34;math inline&#34;&gt;\(y = \gamma_{0} e^{\gamma_{1}x}\)&lt;/span&gt; el coeficiente &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{1}\)&lt;/span&gt; no lo es.&lt;/p&gt;
&lt;p&gt;Dicho esto, el modelo cuadrático de calibración &lt;span class=&#34;math inline&#34;&gt;\(y = \beta_{0} + \beta_{1}x + \beta_{2}x^2\)&lt;/span&gt; &lt;strong&gt;es lineal&lt;/strong&gt; desde el punto de vista estrictamente estadístico. Sin embargo, debido al arraigo del concepto de linealidad en química analítica no modificaremos su interpretación.&lt;/p&gt;
&lt;div id=&#34;test-de-carencia-de-ajuste-lack-of-fit-iso-11095&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Test de carencia de ajuste (&lt;em&gt;Lack of fit&lt;/em&gt;) ISO 11095&lt;/h2&gt;
&lt;p&gt;Este test está basado en comparar dos estimadores del error aleatorio:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Error puro o experimental&lt;/li&gt;
&lt;li&gt;Error de carencia de ajuste o &lt;em&gt;lack of fit&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Es decir, necesitamos un estimador del error aleatorio totalmente independiente del error del modelo de calibración que queremos ajustar. Para estimar este error, la prueba de carencia de ajuste exige que hagamos replicados de cada uno de los calibrantes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Pero tienen que ser replicados verdaderos. No es válido inyectar varias veces el mismo estándar en el equipo. Prepárelos independientemente.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Si los dos estimadores del error aleatorio son similares, entonces el modelo de calibración que acabamos de ajustar es adecuado para modelar los datos experimentales. ¿Cuán similares tienen que ser? Lo probaremos con un test F. Los detalles algebraicos son latosos-engorrosos y pueden ser consultados en la bibliografía. Sólo indicaremos cómo hacer este test de linealidad en lenguaje &lt;code&gt;R&lt;/code&gt;, como no. (¿Y en Excel cuándo?)&lt;/p&gt;
&lt;p&gt;La tabla &lt;a href=&#34;#tab:lof&#34;&gt;1&lt;/a&gt; muestra los datos de calibración de cloranfenicol en matriz leche obtenida por GC/MS-NCI (&lt;em&gt;Gas Chromatography/Mass Spectrometry - Negative Chemical Ionization&lt;/em&gt; …¡Qué tiempos aquellos!). Note que cada nivel de calibración está preparado en triplicado totalizando n = 15 calibrantes independientes. La figura &lt;a href=&#34;#fig:lofplot&#34;&gt;4&lt;/a&gt; muestra la curva de calibración.&lt;/p&gt;
&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:lof&#34;&gt;Table 1: &lt;/span&gt;Calibración CAF [ug/kg]
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Replicado
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.25
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.5
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0.75
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
1
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
88
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7714
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
15292
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
22611
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30280
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
154
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
7726
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
14947
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
22945
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30222
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
512
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
8043
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
15063
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
22772
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
30089
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:lofplot&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-08-23-como-demuestro-que-mi-curva-de-calibracion-es-lineal_files/figure-html/lofplot-1.png&#34; alt=&#34;Curva de calibración CAF. Test de carencia de ajuste&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Curva de calibración CAF. Test de carencia de ajuste
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;La tabla &lt;a href=&#34;#tab:lofcal&#34;&gt;2&lt;/a&gt; muestra el análisis estadístico de esta calibración:&lt;/p&gt;
&lt;!-- Ancho de las tabla --&gt;
&lt;style type=&#34;text/css&#34;&gt;
.table {

    width: 100%;
    
}
&lt;/style&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:lofcal&#34;&gt;Table 2: &lt;/span&gt;Pendiente e intercepto de calibración
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
term
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
estimate
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
std.error
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
statistic
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
p.value
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
262
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.005
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
x.caf
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29936
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
127
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
236
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Por ahora no nos detendremos en el análisis de la tabla (eso quedará para otro post). Haremos directamente el Test de Carencia de Ajuste (&lt;em&gt;lack of fit&lt;/em&gt;) en &lt;code&gt;R&lt;/code&gt; el cual se muestra en la tabla &lt;a href=&#34;#tab:loftest&#34;&gt;3&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(alr3) # Cargamos el package &amp;#39;alr3&amp;#39;
pureErrorAnova(fit.cal)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:loftest&#34;&gt;Table 3: &lt;/span&gt;Tabla de test Carencia de Ajuste
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Df
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Sum Sq
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Mean Sq
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F value
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Pr(&amp;gt;F)
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
x.caf
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1680303154
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1680303154
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54131
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Residuals
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
392486
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
30191
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lack of fit
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
82074
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27358
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.48
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pure Error
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
310412
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31041
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Ok, para interpretar el test de carencia de ajuste nos fijaremos en la fila que dice “&lt;em&gt;Lack of fit&lt;/em&gt;” y en el &lt;em&gt;p-value&lt;/em&gt; del test, el cual aparece bajo la columna &lt;em&gt;Pr(&amp;gt;F)&lt;/em&gt; = 0.48. La interpretación tradicional de una prueba estadística diría algo más o menos así:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Dado que el &lt;em&gt;p-value&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(&amp;gt; 0.05\)&lt;/span&gt;, entonces, no hay evidencias en contra de la hipótesis nula. El modelo lineal es adecuado para modelar los datos de calibración.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Algunas consideraciones:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;¿Dice en alguna parte que el modelo de calibración es lineal? Póngalo de &lt;em&gt;wallpaper&lt;/em&gt; en su pantalla: &lt;strong&gt;NO&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Lo único que se puede extraer como conclusión es que el modelo lineal es adecuado, es razonable para modelar los datos de calibración. Nada más.&lt;/li&gt;
&lt;li&gt;Existen infinitos modelos de calibración que podrían ser idóneos, este test nos dice si el que hemos elegido para modelar los datos es razonable/adecuado, sin embargo, no nos dice que sea “EL” modelo perfecto.&lt;/li&gt;
&lt;li&gt;¿Qué tiene de especial el famoso 0,05? Absolutamente &lt;em&gt;NADA&lt;/em&gt;. ¿Qué concluiría Ud. si el &lt;em&gt;p-value&lt;/em&gt; fuese 0,04999 ó 0,05001? Sería un test totalmente inconcluyente.&lt;/li&gt;
&lt;li&gt;Lamentablemente, esto es una dicotomía perversa que desde hace mucho tiempo ha sido objeto de varias críticas. Le invito a leer las siguientes referencias sobre la interpretación y controversia de los &lt;em&gt;p-values&lt;/em&gt; en ciencia:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Ronald L. Wasserstein &amp;amp; Nicole A. Lazar (2016) The ASA’s Statement on p-Values: Context, Process, and Purpose &lt;em&gt;The American Statistician Volume 70, 2016 - Issue 2&lt;/em&gt; &lt;a href=&#34;http://amstat.tandfonline.com/doi/abs/10.1080/00031305.2016.1154108&#34;&gt;link&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;M.Baker Statisticians issue warning over misuse of P values &lt;em&gt;Nature &lt;strong&gt;531&lt;/strong&gt;, 151 (10 March 2016)&lt;/em&gt; &lt;a href=&#34;http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503&#34;&gt;link&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Singh Chawla D. Big names in statistics want to shake up much-maligned P value. &lt;em&gt;Nature. 2017 Jul 26;548(7665):16-17&lt;/em&gt; &lt;a href=&#34;https://www.nature.com/news/big-names-in-statistics-want-to-shake-up-much-maligned-p-value-1.22375?beta=false&#34;&gt;link&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;“The p-value was never intended to be a substitute for scientific reasoning” Ron Wasserstein, Director Ejecutivo de la Asociación Americana de Estadística ASA.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;test-de-mandel-iso-8466-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Test de Mandel ISO 8466-1&lt;/h2&gt;
&lt;p&gt;Esta prueba estadística es bastante sencilla y está basada en la comparación entre el modelo de calibración lineal y un modelo alternativo. Por lo tanto, no es una prueba absoluta, sino relativa a la elección del modelo alternativo. Require al menos n = 6 calibrantes (sin replicado).&lt;/p&gt;
&lt;p&gt;En general, el test de Mandel utiliza el modelo de calibración cuadrático para compararlo con el modelo lineal:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y = \beta_{0} + \beta_{1}x + \beta_{2}x^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Los detalles estadísticos pueden consultarse en la bibliografía.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Primero calcule la suma de cuadrados de los residuos &lt;span class=&#34;math inline&#34;&gt;\(SS_{r}\)&lt;/span&gt; para cada uno de los modelos de acuerdo a la siguiente expresión:&lt;/li&gt;
&lt;/ol&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:res&#34;&gt;\[\begin{equation}
  SS_{r} = \sum_{i = 1}^{n} e_{i}^2
    \tag{2}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;Donde el residuo &lt;span class=&#34;math inline&#34;&gt;\(e = y - \hat{y}\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; es la respuesta instrumental observada o experimental (áreas, absorbancias, etc.); &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}\)&lt;/span&gt;, es la respuesta instrumental que predice el modelo (lineal o o cuadrático) en cada una de las concentraciones de los calibrantes. Si observa la ecuación &lt;a href=&#34;#eq:res&#34;&gt;(2)&lt;/a&gt; el concepto de residuo es el mismo para cualquier modelo de calibración, es decir, ¿cuánto difiere lo que se observa experimentalmente con lo que predice el modelo?&lt;/p&gt;
&lt;p&gt;Un buen modelo tiene residuos pequeños. Un residuo grande para cierto de nivel de concentración implica que existe una gran diferencia entre lo observado y lo que predice el modelo, por lo tanto, nos guiará (en otro post) a detectar posibles valores anómalos o &lt;em&gt;outliers&lt;/em&gt;.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Calcule la diferencia entre ambas sumas de cuadrado de los residuos, la del modelo no lineal &lt;span class=&#34;math inline&#34;&gt;\(SS_{r}^{no-lin}\)&lt;/span&gt; y la correspondiente al modelo lineal &lt;span class=&#34;math inline&#34;&gt;\(SS_{r}^{lin}\)&lt;/span&gt;:&lt;/li&gt;
&lt;/ol&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:D&#34;&gt;\[\begin{equation}
  D = SS_{r}^{no-lin} -  SS_{r}^{lin}
  \tag{3}
\end{equation}\]&lt;/span&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Estime el estadístico F calculado:&lt;/li&gt;
&lt;/ol&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:D&#34;&gt;\[\begin{equation}
  F = \frac{D}{SS_{r}^{no-lin}/(n - 3)}
  \tag{3}
\end{equation}\]&lt;/span&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Obtenga el F de tabla para 1 grado de libertad en el numerador y &lt;span class=&#34;math inline&#34;&gt;\(n - 3\)&lt;/span&gt; para el denominador&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Compare el &lt;span class=&#34;math inline&#34;&gt;\(F_{calculado}\)&lt;/span&gt; con el &lt;span class=&#34;math inline&#34;&gt;\(F_{tabla}\)&lt;/span&gt; y decida en base a la siguiente regla:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Si &lt;span class=&#34;math inline&#34;&gt;\(F_{calculado} &amp;lt; F_{tabla}\)&lt;/span&gt; se concluye que no hay evidencias en contra de la hipótesis nula de linealidad del modelo. ¿Quiere decir que el modelo de calibración es exactamente lineal? Ya sabemos que &lt;strong&gt;NO&lt;/strong&gt;. Rigen las mismas consideraciones que que notamos en el test de carencia de ajuste.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Si &lt;span class=&#34;math inline&#34;&gt;\(F_{calculado} &amp;gt; F_{tabla}\)&lt;/span&gt; se rechaza la hipótesis nula de linealidad del modelo. Los datos no son consistentes con la hipótesis. Y aquí se abre una caja de Pandora, pues esta conclusión también tiene muchas consideraciones estadísticas que se deben tener en cuenta para interpretarla apropiadamente las cuales, por ahora, no profundizaremos.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Los pasos recién descritos son para llevar a cabo el Test de Mandel “a mano”, afortunadamente los softwares estadísticos como &lt;code&gt;R&lt;/code&gt; y Excel (sí ¡Excel!) tienen incorporada esta prueba estadística de linealidad. Veamos un ejemplo.&lt;/p&gt;
&lt;p&gt;La tabla &lt;a href=&#34;#tab:datamandel&#34;&gt;4&lt;/a&gt; muestra los datos de calibración de Cu por AAS; la figura &lt;a href=&#34;#fig:plotmandel&#34;&gt;5&lt;/a&gt;, la curva de calibración:&lt;/p&gt;
&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; text-align: right;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:datamandel&#34;&gt;Table 4: &lt;/span&gt;Curva de Calibración Cu
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
0
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
10
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
20
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
30
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
40
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
50
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
60
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
70
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
80
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
90
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
100
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-0.007
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.071
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.146
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.212
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.274
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.334
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.385
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.43
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.473
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.511
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.546
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plotmandel&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.analytical.cl/post/2017-08-23-como-demuestro-que-mi-curva-de-calibracion-es-lineal_files/figure-html/plotmandel-1.png&#34; alt=&#34;Curva de calibración Cu&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: Curva de calibración Cu
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;A simple vista se observa la no linealidad de la curva de calibración. Veamos que nos dice el Test de Mandel en la siguiente tabla ANOVA:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# d: corresponde al data frame de los datos de calibración

fit.lin &amp;lt;- lm(y ~ x, data = d) # Ajuste lineal.
fit.nolin &amp;lt;- lm(y ~ x + I(x^2), data = d) # Ajuste no lineal cuadrático

anova(fit.lin, fit.nolin)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Analysis of Variance Table

Model 1: y ~ x
Model 2: y ~ x + I(x^2)
  Res.Df       RSS Df Sum of Sq      F    Pr(&amp;gt;F)    
1      9 0.0054816                                  
2      8 0.0000186  1  0.005463 2351.1 3.621e-11 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;En la tabla el valor &lt;span class=&#34;math inline&#34;&gt;\(F = 2351\)&lt;/span&gt; corresponde al &lt;span class=&#34;math inline&#34;&gt;\(F_{calculado}\)&lt;/span&gt; el cual es comparado internamente con el &lt;span class=&#34;math inline&#34;&gt;\(F_{tabla}\)&lt;/span&gt; entregando, finalmente, el &lt;em&gt;p-value&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(Pr(&amp;gt;F) = 3.62e-11\)&lt;/span&gt;. La evidencia en contra de la hipótesis nula de linealidad es abrumadora.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;entonces-resumiendo-por-que-no-puedo-probar-linealidad-de-la-curva-de-calibracion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Entonces, resumiendo ¿Por qué no puedo probar linealidad de la curva de calibración?&lt;/h1&gt;
&lt;p&gt;Porque la decisión está basada en pruebas estadísticas, las cuáles tienen algunas consideraciones para su correcta interpretación:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Con estas pruebas estadísticas no se puede probar linealidad, lo que podemos concluir es que el modelo lineal es adecuado o razonable para modelar nuestros datos de calibración ¡nada más!.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Es imposible que en un sistema físico-químico complejo como una llama o plasma/detector (ICP-MS) exista una relación “perfectamente” lineal entre absorbancia (cuentas) y concentración. Lo que hicieron Lambert &amp;amp; Beer (o cualquier científico que proponga un modelo de la naturaleza) fue proponer una simplificación del sistema y representarlo mediante un modelo cuantitativo.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Existen muchos modelos que se podrían ajustar muy bien a nuestros datos de calibración, pero en estadística existe el principio de parsimonia:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;En igualdad de condiciones, la explicación más sencilla suele ser la más probable&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;¿Por qué complicarnos la existencia con un modelo hiper-super-parabólico- tangencial si el modelo lineal es razonable y adecuado para nuestros propósitos de cuantificación? Pero ojo:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Everything should be made as simple as possible, but no simpler” – Albert Einstein&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Es aquí donde las pruebas estadísticas nos ayudan a decidir entre varios modelos plausibles.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;en-defensa-del-coeficiente-de-correlacion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;En defensa del coeficiente de correlación&lt;/h1&gt;
&lt;p&gt;Es cierto, el &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; con “muchos” 9’s no es una prueba formal de linealidad… ¿quiere decir que el &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; no es importante en Química Analítica? Por supuesto que sí lo es. Anote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;El coeficiente de correlación está íntimamente ligado con la incertidumbre de calibración. A mayor &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; menor es la incertidumbre de calibración.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Puede profundizar en este aspecto consultando en:&lt;/p&gt;
&lt;p&gt;Ellison, S.L.R. In defense of the correlation coefficient. &lt;em&gt;Accred Qual Assur (2006) 11: 146.&lt;/em&gt; &lt;a href=&#34;https://doi.org/10.1007/s00769-006-0087-y&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1007/s00769-006-0087-y&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;por-ultimo-y-el-r2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Por último… ¿y el &lt;span class=&#34;math inline&#34;&gt;\(r^2\)&lt;/span&gt;?&lt;/h1&gt;
&lt;p&gt;Ahhh, pero eso es otra cosa… hasta la próxima.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bibliografia&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bibliografía&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Lutz Brüggemann, Wolfgang Quapp, Rainer Wennrich &lt;strong&gt;Test for non-linearity concerning linear calibrated chemical measurements&lt;/strong&gt; (2006) &lt;em&gt;Accreditation and Quality Assurance Volume 11, Issue 12, pp 625–631&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;J. M. Andrade and M. P. Gómez-Carracedo &lt;strong&gt;Notes on the use of Mandel’s test to check for nonlinearity in laboratory calibrations&lt;/strong&gt; &lt;em&gt;Anal. Methods, 2013,5, 1145-1149&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
